<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/New_BAI_DataAnalysis/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/New_BAI_DataAnalysis/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li:not(:nth-child(5)) > a, .site-nav > ul.nav-list:first-child > li > ul > li a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(5) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(5) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(5) > ul.nav-list { display: block; } </style> <script src="/New_BAI_DataAnalysis/assets/js/vendor/lunr.min.js"></script> <script src="/New_BAI_DataAnalysis/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>REGRESSION | Data Analysis for Ecologist</title> <meta name="generator" content="Jekyll v3.10.0" /> <meta property="og:title" content="REGRESSION" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="A tutorial for starters learning how to use python to munipulate climate data!" /> <meta property="og:description" content="A tutorial for starters learning how to use python to munipulate climate data!" /> <link rel="canonical" href="https://ericluoyuu.github.io/New_BAI_DataAnalysis/python_3_regression.html" /> <meta property="og:url" content="https://ericluoyuu.github.io/New_BAI_DataAnalysis/python_3_regression.html" /> <meta property="og:site_name" content="Data Analysis for Ecologist" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="REGRESSION" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"A tutorial for starters learning how to use python to munipulate climate data!","headline":"REGRESSION","url":"https://ericluoyuu.github.io/New_BAI_DataAnalysis/python_3_regression.html"}</script> <!-- End Jekyll SEO tag --> </head> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']], displayMath: [ ['$$', '$$'] ], processEscapes: true, processEnvironments: true } }); </script> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"> </script> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/New_BAI_DataAnalysis/" class="site-title lh-tight"> Data Analysis for Ecologist </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/New_BAI_DataAnalysis/" class="nav-list-link">Home</a></li><li class="nav-list-item"><a href="/New_BAI_DataAnalysis/python_0_installation.html" class="nav-list-link">0. INSTALLATION</a></li><li class="nav-list-item"><a href="/New_BAI_DataAnalysis/python_1_basics.html" class="nav-list-link">1. BASICS OF PYTHON</a></li><li class="nav-list-item"><a href="/New_BAI_DataAnalysis/python_2_data_visualization.html" class="nav-list-link">2. DATA HANDLING AND VISUALIZATION</a></li><li class="nav-list-item"><a href="/New_BAI_DataAnalysis/python_3_regression.html" class="nav-list-link">3. REGRESSION</a></li><li class="nav-list-item"><a href="/New_BAI_DataAnalysis/python_4_flux_calculation.html" class="nav-list-link">4. FLUX CALCULATION</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Data Analysis for Ecologist" aria-label="Search Data Analysis for Ecologist" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1 id="regression"> <a href="#regression" class="anchor-heading" aria-labelledby="regression"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>Regression</strong> </h1> <h2 id="table-of-contents"> <a href="#table-of-contents" class="anchor-heading" aria-labelledby="table-of-contents"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Table of Contents </h2> <ul> <li><a href="#chapter-1-whats-regression-all-about">1. What’s Regression All About?</a></li> <li><a href="#chapter-2-simple-linear-regression">2. Simple Linear Regression</a></li> <li><a href="#chapter-3-multiple-regression">3. Multiple Regression</a></li> <li><a href="#chapter-4-machine-learning-with-random-forests">4. Machine Learning with Random Forests</a></li> <li><a href="#chapter-5-filling-gaps-in-time-series">5. Filling Gaps in Time Series</a></li> </ul> <p>Welcome! This tutorial will walk you through regression analysis - one of the most useful tools you’ll encounter for making sense of ecological data. We’ll start from the basics and work our way up to more advanced machine learning methods. Don’t worry if statistics isn’t your strong suit. We’ll take it step by step, and by the end you should feel comfortable applying these techniques to your own data.</p><hr /> <h1 id="1-whats-regression-all-about"> <a href="#1-whats-regression-all-about" class="anchor-heading" aria-labelledby="1-whats-regression-all-about"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>1. What’s Regression All About?</strong> </h1> <h2 id="the-basic-idea"> <a href="#the-basic-idea" class="anchor-heading" aria-labelledby="the-basic-idea"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Basic Idea </h2> <p>Here’s the thing: as ecologists, we’re constantly trying to figure out what drives the patterns we observe. Why are there more species in some places than others? What makes trees grow faster? How does temperature affect animal behavior?</p> <p>Regression gives us a way to quantify these relationships. Instead of just saying “warmer temperatures seem to increase growth,” we can say “for every 1°C increase in temperature, tree ring width increases by 0.15 mm.” That’s powerful stuff.</p> <p>At its core, regression asks: <strong>how does one thing change when another thing changes?</strong></p> <h2 id="a-quick-example"> <a href="#a-quick-example" class="anchor-heading" aria-labelledby="a-quick-example"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> A Quick Example </h2> <p>Let’s say you’re studying tree growth across a temperature gradient. You measure tree ring widths at different sites:</p> <div class="table-wrapper"><table> <thead> <tr> <th>Mean Annual Temperature (°C)</th> <th>Tree Ring Width (mm)</th> </tr> </thead> <tbody> <tr> <td>8</td> <td>1.2</td> </tr> <tr> <td>10</td> <td>1.8</td> </tr> <tr> <td>12</td> <td>2.4</td> </tr> <tr> <td>14</td> <td>2.9</td> </tr> <tr> <td>16</td> <td>3.2</td> </tr> </tbody> </table></div> <p>You can see there’s a pattern - warmer sites have wider rings. But how strong is this relationship? Can we predict growth at a site with 11°C mean temperature? Regression helps us answer these questions.</p> <h2 id="what-can-regression-achieve"> <a href="#what-can-regression-achieve" class="anchor-heading" aria-labelledby="what-can-regression-achieve"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What Can Regression Achieve? </h2> <p>In ecological research, regression is useful for:</p> <p><strong>Making predictions</strong> - You’ve measured carbon flux at 20 sites, but you want to estimate it across the whole landscape. Regression lets you predict values at unmeasured locations based on environmental variables you can get from satellite data.</p> <p><strong>Understanding relationships</strong> - Does nitrogen addition actually increase plant biomass? By how much? Is the effect statistically significant or could it just be noise?</p> <p><strong>Figuring out what matters</strong> - When you have 15 environmental variables that might explain species richness, regression helps you sort out which ones are actually important.</p> <p><strong>Supporting management decisions</strong> - If you know how much habitat area affects population size, you can make informed recommendations about reserve design.</p> <h2 id="terminology"> <a href="#terminology" class="anchor-heading" aria-labelledby="terminology"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Terminology </h2> <p>Before we dive in, let’s get our vocabulary straight. Different fields use different terms for the same things, which can be confusing.</p> <p><strong>Target variable</strong></p> <ul> <li>You can also call it response variable, dependent variable, outcome</li> <li>The variable you’re trying to predict or explain</li> <li>We usually call it <strong>y</strong></li> <li>Examples: species richness, biomass, survival rate, carbon flux</li> </ul> <p><strong>independent variables</strong></p> <ul> <li>Can also be termed predictors, features, independent variables, explanatory variables</li> <li>The variable you use to make predictions or explain target variables</li> <li>We call these <strong>x</strong> (or x₁, x₂, etc. when there are several)</li> <li>Examples: temperature, precipitation, soil pH, elevation</li> </ul> <p><strong>The model:</strong></p> <ul> <li>This is the mathematical equation that describes how x relates to y</li> <li>General form: y = f(x) + error</li> <li>The “error” part is important - it acknowledges that our model won’t be perfect</li> </ul> <p><strong>Coefficients:</strong></p> <ul> <li>These are the numbers in our model that define the relationship</li> <li>In a simple model like y = 3 + 2x, the “3” is the intercept and “2” is the slope</li> <li>We estimate these from our data</li> </ul> <p><strong>Residuals:</strong></p> <ul> <li>The difference between what we observed and what our model predicted</li> <li>Small residuals = good model fit</li> <li>Patterns in residuals = something’s wrong with our model</li> </ul> <h2 id="how-does-regression-actually-work"> <a href="#how-does-regression-actually-work" class="anchor-heading" aria-labelledby="how-does-regression-actually-work"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How Does Regression Actually Work? </h2> <p>The basic process goes like this:</p> <ol> <li> <p><strong>Choose a model type.</strong> Are you assuming a straight line relationship? A curve? Multiple predictors?</p> </li> <li> <p><strong>Fit the model to your data.</strong> This means finding the coefficient values that make your predictions as close to the observations as possible.</p> </li> <li> <p><strong>Check if it worked.</strong> Look at how well the model fits, whether the assumptions are met, and whether the results make ecological sense.</p> </li> </ol> <p>The most common approach for step 2 is called “least squares” - we find the coefficients that minimize the sum of squared differences between observed and predicted values. We square the differences so that positive and negative errors don’t cancel out.</p> <h2 id="evaluating-your-model"> <a href="#evaluating-your-model" class="anchor-heading" aria-labelledby="evaluating-your-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Evaluating Your Model </h2> <p>How do you know if your model is any good? A few key metrics:</p> <p><strong>R² (R-squared)</strong>: This tells you what fraction of the variation in your data is explained by the model. An R² of 0.7 means your model explains 70% of the variance. What’s “good” depends entirely on your system - in controlled experiments 0.9 might be expected, while in field ecology 0.3 might be excellent.</p> <div>$$ R^2 = 1 - \frac{SS_{res}}{SS_{tot}} = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2} $$</div> <p>Where:</p> <p>$y_i$ is the observed value</p> <p>$\hat{y}_i$ is the predicted value</p> <p>$\bar{y}$ is the mean of observed values</p> <p>$SS_{res}$ is the sum of squared residuals</p> <p>$SS_{tot}$ is the total sum of squares</p> <p><strong>RMSE (Root Mean Square Error)</strong>: This is the average size of your prediction errors, in the same units as your response variable. An RMSE of 2.5°C for a temperature model means your predictions are typically off by about 2.5 degrees.</p> <div>$$ RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2} $$</div> <p><strong>MAE (Mean Absolute Error)</strong>: Similar to RMSE but less sensitive to outliers. Useful when you have some weird extreme values in your data.</p> <div>$$ MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i| $$</div> <p>The difference between RMSE and MAE? RMSE penalizes large errors more heavily because of the squaring. If you have a few really bad predictions, RMSE will be much higher than MAE. This can be useful for detecting outliers or problematic predictions.</p><hr /> <h1 id="2-simple-linear-regression"> <a href="#2-simple-linear-regression" class="anchor-heading" aria-labelledby="2-simple-linear-regression"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>2. Simple Linear Regression</strong> </h1> <p>Alright, let’s actually do some regression. We’ll start with the simplest case: one predictor, one response, straight line relationship.</p> <h2 id="the-model"> <a href="#the-model" class="anchor-heading" aria-labelledby="the-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Model </h2> <p>Simple linear regression fits this equation:</p> <p><strong>y = β₀ + β₁x</strong></p> <p>Where:</p> <ul> <li><strong>β₀</strong> is the intercept (value of y when x is zero)</li> <li><strong>β₁</strong> is the slope (how much y changes for each unit increase in x)</li> </ul> <p>That’s it. We’re just fitting a line through our data points.</p> <h2 id="lets-try-it-tree-growth-and-temperature"> <a href="#lets-try-it-tree-growth-and-temperature" class="anchor-heading" aria-labelledby="lets-try-it-tree-growth-and-temperature"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Let’s Try It: Tree Growth and Temperature </h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="n">px</span>
<span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="n">go</span>

<span class="c1"># Here's some tree ring data from a temperature gradient
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">temperature</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">])</span>
<span class="n">ring_width</span> <span class="o">=</span> <span class="mf">0.8</span> <span class="o">+</span> <span class="mf">0.15</span> <span class="o">*</span> <span class="n">temperature</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">temperature</span><span class="p">))</span>

<span class="n">tree_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s">'temperature_C'</span><span class="p">:</span> <span class="n">temperature</span><span class="p">,</span>
    <span class="s">'ring_width_mm'</span><span class="p">:</span> <span class="n">ring_width</span>
<span class="p">})</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Our data:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tree_data</span><span class="p">)</span>
</code></pre></div></div> <p>Now let’s fit a regression. I’ll show you both the manual calculation and the easy way with scikit-learn.</p> <h3 id="the-math-for-those-who-want-it"> <a href="#the-math-for-those-who-want-it" class="anchor-heading" aria-labelledby="the-math-for-those-who-want-it"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Math (for those who want it) </h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Calculate means
</span><span class="n">temp_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">temperature</span><span class="p">)</span>
<span class="n">growth_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ring_width</span><span class="p">)</span>

<span class="c1"># Slope formula
</span><span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">temperature</span> <span class="o">-</span> <span class="n">temp_mean</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">ring_width</span> <span class="o">-</span> <span class="n">growth_mean</span><span class="p">))</span>
<span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">temperature</span> <span class="o">-</span> <span class="n">temp_mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">slope</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>

<span class="c1"># Intercept
</span><span class="n">intercept</span> <span class="o">=</span> <span class="n">growth_mean</span> <span class="o">-</span> <span class="n">slope</span> <span class="o">*</span> <span class="n">temp_mean</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Slope: </span><span class="si">{</span><span class="n">slope</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> mm per °C"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Intercept: </span><span class="si">{</span><span class="n">intercept</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> mm"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="the-easy-way"> <a href="#the-easy-way" class="anchor-heading" aria-labelledby="the-easy-way"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Easy Way </h3> <p>In practice, you’ll almost always use a library:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># sklearn wants 2D arrays, hence the reshape
</span><span class="n">X</span> <span class="o">=</span> <span class="n">temperature</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ring_width</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Slope: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> mm per °C"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Intercept: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">intercept_</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> mm"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"R-squared: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="what-do-these-numbers-mean"> <a href="#what-do-these-numbers-mean" class="anchor-heading" aria-labelledby="what-do-these-numbers-mean"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What Do These Numbers Mean? </h3> <p>The slope of about 0.15 tells us that for every 1°C increase in mean annual temperature, tree ring width increases by roughly 0.15 mm. That’s the key ecological finding here.</p> <p>The intercept (around 0.8) would be the predicted ring width at 0°C. This doesn’t make much biological sense - trees don’t really grow at 0°C - but mathematically we need it to define our line.</p> <p>The R² of around 0.75 tells us that temperature explains about 75% of the variation in ring width. Not bad! The remaining 25% is due to other factors we haven’t measured (soil quality, genetics, competition, etc.) plus measurement error.</p> <h3 id="visualizing-the-fit"> <a href="#visualizing-the-fit" class="anchor-heading" aria-labelledby="visualizing-the-fit"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Visualizing the Fit </h3> <p>Always plot your regression. Numbers alone can be misleading.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Get predictions
</span><span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="n">Figure</span><span class="p">()</span>

<span class="c1"># Data points
</span><span class="n">fig</span><span class="p">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="n">Scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">ring_width</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s">'markers'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'Observations'</span><span class="p">,</span>
    <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'forestgreen'</span><span class="p">)</span>
<span class="p">))</span>

<span class="c1"># Regression line
</span><span class="n">fig</span><span class="p">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="n">Scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">predicted</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s">'lines'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'Fitted line'</span><span class="p">,</span>
    <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s">'darkgreen'</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="p">))</span>

<span class="n">fig</span><span class="p">.</span><span class="n">update_layout</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s">'Tree Growth vs Temperature'</span><span class="p">,</span>
    <span class="n">xaxis_title</span><span class="o">=</span><span class="s">'Mean Annual Temperature (°C)'</span><span class="p">,</span>
    <span class="n">yaxis_title</span><span class="o">=</span><span class="s">'Ring Width (mm)'</span><span class="p">,</span>
    <span class="n">template</span><span class="o">=</span><span class="s">'simple_white'</span>
<span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <div style="background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin-bottom: 5px;"> <div class="notice--primary"> <h3> <a href="#visualizing-the-fit" class="anchor-heading" aria-labelledby="visualizing-the-fit"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Try It Yourself </h3> <p>Create a dataset for grassland productivity (kg/ha) vs annual precipitation (mm). Fit a regression and interpret the slope. What does it tell you about water limitation?</p> <details> <summary>Solution!</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Precipitation gradient
</span><span class="n">precip</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">400</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">600</span><span class="p">,</span> <span class="mi">700</span><span class="p">,</span> <span class="mi">800</span><span class="p">,</span> <span class="mi">900</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1100</span><span class="p">])</span>
<span class="c1"># Biomass increases with rainfall (with some noise)
</span><span class="n">biomass</span> <span class="o">=</span> <span class="mi">500</span> <span class="o">+</span> <span class="mf">3.5</span> <span class="o">*</span> <span class="n">precip</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">precip</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">precip</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">biomass</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Slope: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> kg/ha per mm rainfall"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"R-squared: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">precip</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">biomass</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># The slope tells us that each additional mm of rainfall 
# gives us about 3.5 kg/ha more biomass. This is essentially
# a measure of rainfall use efficiency for this grassland.
</span></code></pre></div> </div> </details> </div> </div> <h2 id="limitations"> <a href="#limitations" class="anchor-heading" aria-labelledby="limitations"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Limitations </h2> <p>Simple regression is great, but it has obvious limitations. Ecological systems are complex - tree growth isn’t just about temperature. There’s precipitation, soil nutrients, competition, pests, genetics…</p> <p>Also, the relationship might not be linear. Many ecological relationships have thresholds or optima. Trees don’t just keep growing faster forever as temperature increases - at some point it gets too hot.</p> <p>That’s where multiple regression and machine learning come in.</p><hr /> <h1 id="3-multiple-regression"> <a href="#3-multiple-regression" class="anchor-heading" aria-labelledby="3-multiple-regression"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>3. Multiple Regression</strong> </h1> <p>In the real world, ecological responses depend on many factors simultaneously. Multiple regression lets us include all of them in one model.</p> <h2 id="why-go-multiple"> <a href="#why-go-multiple" class="anchor-heading" aria-labelledby="why-go-multiple"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Why Go Multiple? </h2> <p>Think about what controls ecosystem carbon exchange:</p> <ul> <li>Light drives photosynthesis</li> <li>Temperature affects both photosynthesis and respiration</li> <li>Soil moisture determines water availability</li> <li>Humidity influences stomatal conductance</li> </ul> <p>If we only model carbon flux against temperature, we’re missing most of the picture. Multiple regression lets us ask: “what’s the effect of temperature, <em>after accounting for</em> light, moisture, and humidity?”</p> <h2 id="the-model-1"> <a href="#the-model-1" class="anchor-heading" aria-labelledby="the-model-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Model </h2> <p>We extend our simple model to include multiple predictors:</p> <p><strong>y = β₀ + β₁x₁ + β₂x₂ + β₃x₃ + …</strong></p> <p>Each coefficient now tells us the effect of that variable <em>while holding the others constant</em>. This is crucial for interpretation.</p> <h2 id="example-forest-carbon-flux"> <a href="#example-forest-carbon-flux" class="anchor-heading" aria-labelledby="example-forest-carbon-flux"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Example: Forest Carbon Flux </h2> <p>Let’s build a model for net ecosystem exchange (NEE) - the balance between carbon uptake and release.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="n">metrics</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">300</span>

<span class="c1"># Environmental drivers
</span><span class="n">solar_rad</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">900</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>       <span class="c1"># W/m²
</span><span class="n">air_temp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>           <span class="c1"># °C
</span><span class="n">soil_moisture</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>     <span class="c1"># %
</span><span class="n">vpd</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>               <span class="c1"># kPa (vapor pressure deficit)
</span>
<span class="c1"># Carbon flux - negative means uptake, positive means release
# These relationships are roughly realistic
</span><span class="n">nee</span> <span class="o">=</span> <span class="p">(</span>
    <span class="mi">5</span> <span class="o">-</span>                           <span class="c1"># baseline respiration
</span>    <span class="mf">0.015</span> <span class="o">*</span> <span class="n">solar_rad</span> <span class="o">+</span>           <span class="c1"># light drives uptake
</span>    <span class="mf">0.3</span> <span class="o">*</span> <span class="n">air_temp</span> <span class="o">+</span>              <span class="c1"># warmth increases respiration  
</span>    <span class="o">-</span><span class="mf">0.1</span> <span class="o">*</span> <span class="n">soil_moisture</span> <span class="o">+</span>        <span class="c1"># moisture supports uptake
</span>    <span class="mf">2.0</span> <span class="o">*</span> <span class="n">vpd</span> <span class="o">+</span>                   <span class="c1"># high VPD closes stomata, reduces uptake
</span>    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>   <span class="c1"># noise
</span><span class="p">)</span>

<span class="n">flux_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s">'solar_radiation'</span><span class="p">:</span> <span class="n">solar_rad</span><span class="p">,</span>
    <span class="s">'air_temperature'</span><span class="p">:</span> <span class="n">air_temp</span><span class="p">,</span>
    <span class="s">'soil_moisture'</span><span class="p">:</span> <span class="n">soil_moisture</span><span class="p">,</span>
    <span class="s">'vpd'</span><span class="p">:</span> <span class="n">vpd</span><span class="p">,</span>
    <span class="s">'nee'</span><span class="p">:</span> <span class="n">nee</span>
<span class="p">})</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Dataset preview:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">flux_data</span><span class="p">.</span><span class="n">head</span><span class="p">())</span>
</code></pre></div></div> <h3 id="check-correlations-first"> <a href="#check-correlations-first" class="anchor-heading" aria-labelledby="check-correlations-first"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Check Correlations First </h3> <p>Before modeling, it’s always good to see how variables relate to each other:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Correlations with NEE:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">flux_data</span><span class="p">.</span><span class="n">corr</span><span class="p">()[</span><span class="s">'nee'</span><span class="p">].</span><span class="n">sort_values</span><span class="p">())</span>
</code></pre></div></div> <p>This gives you a first sense of which variables might be important predictors.</p> <h3 id="fitting-the-model"> <a href="#fitting-the-model" class="anchor-heading" aria-labelledby="fitting-the-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Fitting the Model </h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Prepare our data
</span><span class="n">X</span> <span class="o">=</span> <span class="n">flux_data</span><span class="p">[[</span><span class="s">'solar_radiation'</span><span class="p">,</span> <span class="s">'air_temperature'</span><span class="p">,</span> <span class="s">'soil_moisture'</span><span class="p">,</span> <span class="s">'vpd'</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">flux_data</span><span class="p">[</span><span class="s">'nee'</span><span class="p">]</span>

<span class="c1"># Always split into training and test sets!
# This is how we honestly evaluate our model
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Fit the model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Look at the coefficients
</span><span class="k">print</span><span class="p">(</span><span class="s">"Model coefficients:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Intercept: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">intercept_</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">coef</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="interpreting-the-results"> <a href="#interpreting-the-results" class="anchor-heading" aria-labelledby="interpreting-the-results"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Interpreting the Results </h3> <p>This is the important part. What do these numbers actually mean?</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"""
What the coefficients tell us:

Solar radiation (-0.015): Each additional W/m² of radiation 
  decreases NEE by 0.015 µmol/m²/s. Negative because more light 
  means more photosynthesis, which is carbon uptake.

Air temperature (+0.30): Each degree warmer increases NEE by 
  0.30 µmol/m²/s. Positive because warmth stimulates respiration 
  more than photosynthesis in this model.

Soil moisture (-0.10): Wetter soils decrease NEE (more uptake).
  Makes sense - water stress limits productivity.

VPD (+2.0): High vapor pressure deficit increases NEE. When 
  the air is dry, plants close their stomata to conserve water,
  which also blocks CO2 uptake.
"""</span><span class="p">)</span>
</code></pre></div></div> <h3 id="how-good-is-our-model"> <a href="#how-good-is-our-model" class="anchor-heading" aria-labelledby="how-good-is-our-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How Good Is Our Model? </h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Predict on test data (data the model hasn't seen)
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">r2</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"R-squared: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"RMSE: </span><span class="si">{</span><span class="n">rmse</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> µmol/m²/s"</span><span class="p">)</span>

<span class="c1"># Plot predicted vs observed
</span><span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="n">px</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
                 <span class="n">labels</span><span class="o">=</span><span class="p">{</span><span class="s">'x'</span><span class="p">:</span> <span class="s">'Observed NEE'</span><span class="p">,</span> <span class="s">'y'</span><span class="p">:</span> <span class="s">'Predicted NEE'</span><span class="p">})</span>
<span class="c1"># Add 1:1 line
</span><span class="n">fig</span><span class="p">.</span><span class="n">add_scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="n">y_test</span><span class="p">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">y_test</span><span class="p">.</span><span class="nb">max</span><span class="p">()],</span> 
                <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="n">y_test</span><span class="p">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">y_test</span><span class="p">.</span><span class="nb">max</span><span class="p">()],</span>
                <span class="n">mode</span><span class="o">=</span><span class="s">'lines'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'1:1 line'</span><span class="p">,</span>
                <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">dash</span><span class="o">=</span><span class="s">'dash'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">))</span>
<span class="n">fig</span><span class="p">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="s">'simple_white'</span><span class="p">,</span> 
                  <span class="n">title</span><span class="o">=</span><span class="s">'How well does our model predict?'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <h3 id="does-adding-variables-help"> <a href="#does-adding-variables-help" class="anchor-heading" aria-labelledby="does-adding-variables-help"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Does Adding Variables Help? </h3> <p>A natural question: does including more predictors actually improve our model?</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Let's compare models with different numbers of predictors
</span><span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Just solar radiation
</span><span class="n">m1</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s">'solar_radiation'</span><span class="p">]],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Model'</span><span class="p">:</span> <span class="s">'Solar only'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">m1</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="s">'solar_radiation'</span><span class="p">]],</span> <span class="n">y_test</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># Solar + temperature
</span><span class="n">m2</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s">'solar_radiation'</span><span class="p">,</span> <span class="s">'air_temperature'</span><span class="p">]],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Model'</span><span class="p">:</span> <span class="s">'Solar + Temp'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">m2</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="s">'solar_radiation'</span><span class="p">,</span> <span class="s">'air_temperature'</span><span class="p">]],</span> <span class="n">y_test</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># All four
</span><span class="n">m4</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Model'</span><span class="p">:</span> <span class="s">'All four'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">m4</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="p">})</span>

<span class="k">print</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">))</span>
</code></pre></div></div> <p>Usually, adding relevant predictors helps. But be careful - adding irrelevant variables can actually hurt your model’s ability to generalize to new data (this is called overfitting).</p> <div style="background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin-bottom: 5px;"> <div class="notice--primary"> <h3> <a href="#does-adding-variables-help" class="anchor-heading" aria-labelledby="does-adding-variables-help"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Try It Yourself </h3> <p>Build a model predicting fish species richness in lakes based on: lake area, maximum depth, water temperature, and dissolved oxygen. Which factor matters most?</p> <details> <summary>Solution!</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">150</span>

<span class="n">area</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>          <span class="c1"># hectares
</span><span class="n">depth</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>            <span class="c1"># meters  
</span><span class="n">temp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>            <span class="c1"># °C
</span><span class="n">oxygen</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>           <span class="c1"># mg/L
</span>
<span class="c1"># Species richness - larger, deeper lakes with good oxygen have more species
</span><span class="n">richness</span> <span class="o">=</span> <span class="p">(</span>
    <span class="mi">5</span> <span class="o">+</span> <span class="mf">0.005</span> <span class="o">*</span> <span class="n">area</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">depth</span> <span class="o">+</span> 
    <span class="o">-</span><span class="mf">0.1</span> <span class="o">*</span> <span class="p">(</span><span class="n">temp</span> <span class="o">-</span> <span class="mi">18</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span>  <span class="c1"># optimum around 18°C
</span>    <span class="mf">1.5</span> <span class="o">*</span> <span class="n">oxygen</span> <span class="o">+</span> 
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="p">).</span><span class="n">clip</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'area'</span><span class="p">:</span> <span class="n">area</span><span class="p">,</span> <span class="s">'depth'</span><span class="p">:</span> <span class="n">depth</span><span class="p">,</span> <span class="s">'temp'</span><span class="p">:</span> <span class="n">temp</span><span class="p">,</span> <span class="s">'oxygen'</span><span class="p">:</span> <span class="n">oxygen</span><span class="p">})</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">richness</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"R²: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Coefficients (larger absolute value = more important):"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">),</span> 
                         <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">abs</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">coef</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Oxygen usually comes out strongest - makes ecological sense
# since it's essential for fish survival
</span></code></pre></div> </div> </details> </div> </div> <h2 id="limitations-1"> <a href="#limitations-1" class="anchor-heading" aria-labelledby="limitations-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Limitations </h2> <p>Multiple regression is powerful but has some important limitations:</p> <p><strong>It assumes linear relationships.</strong> If temperature has an optimum (growth increases up to 25°C then decreases), a linear model won’t capture that properly.</p> <p><strong>It assumes additive effects.</strong> The model says the effect of temperature is the same regardless of moisture levels. In reality, these factors often interact.</p> <p><strong>It can struggle with many predictors.</strong> If you have 50 environmental variables and only 100 observations, you’re going to have problems.</p> <p>These limitations bring us to machine learning approaches, which can handle more complexity.</p><hr /> <h1 id="4-machine-learning-with-random-forests"> <a href="#4-machine-learning-with-random-forests" class="anchor-heading" aria-labelledby="4-machine-learning-with-random-forests"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>4. Machine Learning with Random Forests</strong> </h1> <p>Alright, now we’re getting to the fun stuff. Machine learning sounds fancy, but the basic idea is simple: let the algorithm figure out the patterns in your data, rather than you specifying them in advance.</p> <h2 id="why-machine-learning"> <a href="#why-machine-learning" class="anchor-heading" aria-labelledby="why-machine-learning"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Why Machine Learning? </h2> <p>Ecological relationships are often messy:</p> <ul> <li>Species have thermal optima, not just linear responses</li> <li>Effects of one variable depend on another (interactions)</li> <li>There might be thresholds or nonlinearities we didn’t anticipate</li> </ul> <p>Machine learning algorithms can discover these patterns automatically. You don’t have to know the shape of the relationship beforehand.</p> <h2 id="decision-trees-the-building-block"> <a href="#decision-trees-the-building-block" class="anchor-heading" aria-labelledby="decision-trees-the-building-block"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Decision Trees: The Building Block </h2> <p>Before we get to Random Forests, we need to understand decision trees. They’re intuitive once you see how they work.</p> <p>A decision tree is basically a flowchart of questions:</p> <ul> <li>Is temperature &gt; 15°C? <ul> <li>Yes → Is rainfall &gt; 500mm? <ul> <li>Yes → Predict high productivity</li> <li>No → Predict medium productivity</li> </ul> </li> <li>No → Predict low productivity</li> </ul> </li> </ul> <p>The algorithm figures out which questions to ask and what thresholds to use by looking at your data.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span><span class="p">,</span> <span class="n">plot_tree</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Using our carbon flux data from before
</span><span class="n">X</span> <span class="o">=</span> <span class="n">flux_data</span><span class="p">[[</span><span class="s">'solar_radiation'</span><span class="p">,</span> <span class="s">'air_temperature'</span><span class="p">,</span> <span class="s">'soil_moisture'</span><span class="p">,</span> <span class="s">'vpd'</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">flux_data</span><span class="p">[</span><span class="s">'nee'</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Fit a simple tree (max_depth limits how many questions it asks)
</span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tree</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Visualize it
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Decision Tree for Carbon Flux'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Tree R²: </span><span class="si">{</span><span class="n">tree</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <p>Decision trees are easy to interpret - you can literally see the rules. But they have a problem: they tend to overfit. A deep tree can memorize the training data perfectly but fail miserably on new data.</p> <h2 id="random-forests-many-trees-are-better-than-one"> <a href="#random-forests-many-trees-are-better-than-one" class="anchor-heading" aria-labelledby="random-forests-many-trees-are-better-than-one"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Random Forests: Many Trees Are Better Than One </h2> <p>Random Forests solve the overfitting problem by building many trees and averaging their predictions. Each tree is a bit different because:</p> <ol> <li>Each tree is trained on a random subset of the data (with replacement)</li> <li>At each split, only a random subset of variables is considered</li> </ol> <p>This randomness means individual trees might make mistakes, but averaging over hundreds of trees gives robust predictions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="c1"># Fit a random forest
</span><span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>    <span class="c1"># number of trees
</span>    <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>        <span class="c1"># how deep each tree can go
</span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
<span class="n">rf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluate
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Random Forest R²: </span><span class="si">{</span><span class="n">metrics</span><span class="p">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Random Forest RMSE: </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <h2 id="comparing-all-our-methods"> <a href="#comparing-all-our-methods" class="anchor-heading" aria-labelledby="comparing-all-our-methods"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Comparing All Our Methods </h2> <p>Let’s see how everything stacks up:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Simple regression (just one predictor)
</span><span class="n">simple</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">simple</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s">'solar_radiation'</span><span class="p">]],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">simple</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="s">'solar_radiation'</span><span class="p">]])</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Method'</span><span class="p">:</span> <span class="s">'Simple regression'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">metrics</span><span class="p">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">),</span>
    <span class="s">'RMSE'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="p">})</span>

<span class="c1"># Multiple regression
</span><span class="n">multi</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">multi</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">multi</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Method'</span><span class="p">:</span> <span class="s">'Multiple regression'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">metrics</span><span class="p">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">),</span>
    <span class="s">'RMSE'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="p">})</span>

<span class="c1"># Decision tree
</span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tree</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">tree</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Method'</span><span class="p">:</span> <span class="s">'Decision tree'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">metrics</span><span class="p">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">),</span>
    <span class="s">'RMSE'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="p">})</span>

<span class="c1"># Random forest
</span><span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">rf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Method'</span><span class="p">:</span> <span class="s">'Random forest'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">metrics</span><span class="p">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">),</span>
    <span class="s">'RMSE'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="p">})</span>

<span class="k">print</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">).</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
</code></pre></div></div> <h2 id="whats-driving-the-patterns"> <a href="#whats-driving-the-patterns" class="anchor-heading" aria-labelledby="whats-driving-the-patterns"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What’s Driving the Patterns? </h2> <p>One of the nicest things about Random Forests is that they tell you which variables matter most:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">importance</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s">'Variable'</span><span class="p">:</span> <span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="s">'Importance'</span><span class="p">:</span> <span class="n">rf</span><span class="p">.</span><span class="n">feature_importances_</span>
<span class="p">}).</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Importance'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Variable importance:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">importance</span><span class="p">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>

<span class="c1"># Plot it
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Importance'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'Variable'</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s">'h'</span><span class="p">,</span>
             <span class="n">title</span><span class="o">=</span><span class="s">'What drives carbon flux?'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="s">'simple_white'</span><span class="p">,</span> <span class="n">yaxis</span><span class="o">=</span><span class="p">{</span><span class="s">'categoryorder'</span><span class="p">:</span> <span class="s">'total ascending'</span><span class="p">})</span>
<span class="n">fig</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <p>This is ecologically valuable - it tells you which environmental factors to focus on in future research or monitoring.</p> <h2 id="tuning-your-forest"> <a href="#tuning-your-forest" class="anchor-heading" aria-labelledby="tuning-your-forest"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Tuning Your Forest </h2> <p>Random Forests have some settings (hyperparameters) you can adjust:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># How many trees do we need?
</span><span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">n_trees</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">]:</span>
    <span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">n_trees</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">rf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s">'Trees'</span><span class="p">:</span> <span class="n">n_trees</span><span class="p">,</span>
        <span class="s">'R²'</span><span class="p">:</span> <span class="n">rf</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="p">})</span>

<span class="k">print</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">))</span>
<span class="c1"># Usually performance plateaus around 100-200 trees
</span></code></pre></div></div> <p>The main parameters to consider:</p> <ul> <li><strong>n_estimators</strong>: More trees = better but slower. 100-500 is usually fine.</li> <li><strong>max_depth</strong>: Deeper trees can capture more complexity but might overfit.</li> <li><strong>min_samples_leaf</strong>: Requiring more samples per leaf prevents overfitting.</li> </ul> <div style="background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin-bottom: 5px;"> <div class="notice--primary"> <h3> <a href="#tuning-your-forest" class="anchor-heading" aria-labelledby="tuning-your-forest"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Try It Yourself </h3> <p>Build a Random Forest to predict plant species richness from soil pH, nitrogen, precipitation, and grazing intensity. Compare it to multiple regression. Which variables matter most for plant diversity?</p> <details> <summary>Solution!</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">200</span>

<span class="n">soil_ph</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">4.5</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">nitrogen</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">precip</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">1200</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">grazing</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

<span class="c1"># Non-linear relationships - this is where RF should shine
</span><span class="n">richness</span> <span class="o">=</span> <span class="p">(</span>
    <span class="mi">20</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">soil_ph</span> <span class="o">-</span> <span class="mf">6.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span>      <span class="c1"># optimum pH around 6.5
</span>    <span class="o">-</span><span class="mf">0.0005</span><span class="o">*</span><span class="p">(</span><span class="n">nitrogen</span> <span class="o">-</span> <span class="mi">50</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span>      <span class="c1"># intermediate N best
</span>    <span class="mf">0.01</span><span class="o">*</span><span class="n">precip</span> <span class="o">+</span>                     <span class="c1"># more rain helps
</span>    <span class="mi">5</span><span class="o">*</span><span class="n">grazing</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">grazing</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span>        <span class="c1"># moderate grazing best
</span>    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="p">).</span><span class="n">clip</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s">'soil_ph'</span><span class="p">:</span> <span class="n">soil_ph</span><span class="p">,</span> <span class="s">'nitrogen'</span><span class="p">:</span> <span class="n">nitrogen</span><span class="p">,</span>
    <span class="s">'precipitation'</span><span class="p">:</span> <span class="n">precip</span><span class="p">,</span> <span class="s">'grazing'</span><span class="p">:</span> <span class="n">grazing</span>
<span class="p">})</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">richness</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Multiple regression
</span><span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Multiple regression R²: </span><span class="si">{</span><span class="n">lr</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Random forest
</span><span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Random Forest R²: </span><span class="si">{</span><span class="n">rf</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Variable importance:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">imp</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">rf</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">),</span> 
                        <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">imp</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># RF should do better because of the non-linear relationships
# soil_ph and grazing are probably most important due to their 
# strong non-linear effects
</span></code></pre></div> </div> </details> </div> </div> <h2 id="when-to-use-what"> <a href="#when-to-use-what" class="anchor-heading" aria-labelledby="when-to-use-what"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> When to Use What? </h2> <p>Here’s my rough guide:</p> <div class="table-wrapper"><table> <thead> <tr> <th>Situation</th> <th>Method</th> </tr> </thead> <tbody> <tr> <td>Simple exploratory analysis</td> <td>Simple regression</td> </tr> <tr> <td>Need interpretable coefficients</td> <td>Multiple regression</td> </tr> <tr> <td>Complex patterns, many variables</td> <td>Random Forest</td> </tr> <tr> <td>Small dataset (&lt;50 samples)</td> <td>Stick to regression</td> </tr> <tr> <td>Need to explain to non-statisticians</td> <td>Decision tree or regression</td> </tr> <tr> <td>Just want the best predictions</td> <td>Random Forest</td> </tr> </tbody> </table></div> <p>In practice, I often fit both multiple regression and Random Forest. The regression gives me interpretable coefficients, while Random Forest tells me if there’s predictive signal I’m missing with the linear model.</p><hr /> <h1 id="5-gap-filling-in-time-series"> <a href="#5-gap-filling-in-time-series" class="anchor-heading" aria-labelledby="5-gap-filling-in-time-series"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>5. Gap-filling in Time Series</strong> </h1> <p>Now let’s apply what we’ve learned to a practical problem: dealing with missing data in ecological time series.</p> <h2 id="the-problem"> <a href="#the-problem" class="anchor-heading" aria-labelledby="the-problem"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Problem </h2> <p>If you’ve worked with field data, you know this frustration. Your sensor died for a week. The battery ran out during the coldest part of winter. Someone accidentally unplugged the datalogger.</p> <p>Missing data is annoying because:</p> <ul> <li>You can’t calculate annual totals or means</li> <li>It messes up time series analyses</li> <li>Some statistical methods can’t handle NaN values</li> </ul> <h2 id="loading-messy-data"> <a href="#loading-messy-data" class="anchor-heading" aria-labelledby="loading-messy-data"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Loading Messy Data </h2> <p>Real data often has placeholder values instead of proper missing data markers. Let’s see an example:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Load meteorological data
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="s">'./dwd_ahaus_1996_2023_missing_placeholders.parquet'</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"data_time"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"data_time"</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Temperature range: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">].</span><span class="nb">min</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s"> to </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <p>If you see -999.99 as the minimum, that’s a placeholder for missing data - not an actual temperature! We need to fix this:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Replace placeholder with NaN
</span><span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">"tair_2m_mean"</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mf">999.99</span><span class="p">,</span> <span class="s">"tair_2m_mean"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">NaN</span>

<span class="c1"># Now check
</span><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Missing values: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">].</span><span class="n">isna</span><span class="p">().</span><span class="nb">sum</span><span class="p">()</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <h2 id="method-1-linear-interpolation"> <a href="#method-1-linear-interpolation" class="anchor-heading" aria-labelledby="method-1-linear-interpolation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Method 1: Linear Interpolation </h2> <p>The simplest approach - just draw a straight line between known values:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Pandas makes this easy
</span><span class="n">df</span><span class="p">[</span><span class="s">'temp_interp'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">].</span><span class="n">interpolate</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">'linear'</span><span class="p">)</span>
</code></pre></div></div> <p>This works fine for short gaps. If temperature was 10°C at noon and 14°C at 2pm, it’s reasonable to guess 12°C at 1pm.</p> <p>But it fails badly for longer gaps. It can’t capture the daily temperature cycle - if you have a 24-hour gap, linear interpolation will give you a flat line right through where the daily max and min should be.</p> <h2 id="method-2-regression-based-gap-filling"> <a href="#method-2-regression-based-gap-filling" class="anchor-heading" aria-labelledby="method-2-regression-based-gap-filling"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Method 2: Regression-Based Gap Filling </h2> <p>If we have other variables that were measured continuously, we can use them to estimate the missing temperatures:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># Solar radiation and humidity are often available when temperature fails
# (different sensors)
</span><span class="n">predictors</span> <span class="o">=</span> <span class="p">[</span><span class="s">'SWIN'</span><span class="p">,</span> <span class="s">'rH'</span><span class="p">]</span>

<span class="c1"># Get data where everything is present (for training)
</span><span class="n">df_complete</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'data_time'</span><span class="p">,</span> <span class="s">'SWIN'</span><span class="p">,</span> <span class="s">'rH'</span><span class="p">,</span> <span class="s">'tair_2m_mean'</span><span class="p">]].</span><span class="n">dropna</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_complete</span><span class="p">[</span><span class="n">predictors</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_complete</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">]</span>

<span class="c1"># Fit model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Gap-filling model R²: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <p>Then we can predict temperature wherever we have radiation and humidity data:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Find rows where temp is missing but predictors exist
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">].</span><span class="n">isna</span><span class="p">()</span> <span class="o">&amp;</span> <span class="n">df</span><span class="p">[</span><span class="s">'SWIN'</span><span class="p">].</span><span class="n">notna</span><span class="p">()</span> <span class="o">&amp;</span> <span class="n">df</span><span class="p">[</span><span class="s">'rH'</span><span class="p">].</span><span class="n">notna</span><span class="p">()</span>
<span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="s">'temp_regression'</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="n">predictors</span><span class="p">])</span>
</code></pre></div></div> <h2 id="method-3-random-forest-gap-filling"> <a href="#method-3-random-forest-gap-filling" class="anchor-heading" aria-labelledby="method-3-random-forest-gap-filling"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Method 3: Random Forest Gap Filling </h2> <p>For better accuracy, especially with complex patterns, Random Forest often wins:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="c1"># Use more predictors
</span><span class="n">all_predictors</span> <span class="o">=</span> <span class="p">[</span><span class="s">'SWIN'</span><span class="p">,</span> <span class="s">'rH'</span><span class="p">,</span> <span class="s">'pressure_air'</span><span class="p">,</span> <span class="s">'wind_speed'</span><span class="p">,</span> <span class="s">'precipitation'</span><span class="p">]</span>
<span class="n">df_complete</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">all_predictors</span> <span class="o">+</span> <span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">]].</span><span class="n">dropna</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_complete</span><span class="p">[</span><span class="n">all_predictors</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_complete</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">]</span>

<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Random Forest R²: </span><span class="si">{</span><span class="n">rf</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Check which predictors matter most for estimating temperature
</span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">imp</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">all_predictors</span><span class="p">,</span> <span class="n">rf</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">),</span> 
                        <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">imp</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <h2 id="which-method-when"> <a href="#which-method-when" class="anchor-heading" aria-labelledby="which-method-when"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Which Method When? </h2> <p>After working with a lot of gap-filled data, here’s what I’ve found:</p> <p><strong>Short gaps (a few hours):</strong> Linear interpolation is usually fine. Temperature doesn’t change that fast.</p> <p><strong>Medium gaps (a day or two):</strong> Regression with environmental predictors. This captures the daily cycle if you have radiation data.</p> <p><strong>Long gaps (weeks+):</strong> Random Forest or similar, but honestly… consider whether you should be filling such long gaps at all. Sometimes it’s better to acknowledge the data is missing.</p> <p><strong>General advice:</strong></p> <ul> <li>Always validate your gap-filling on data where you know the truth</li> <li>Flag gap-filled values in your final dataset</li> <li>Report the uncertainty or error in your gap-filled values</li> <li>Don’t over-fill - sometimes missing data should stay missing</li> </ul> <div style="background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin-bottom: 5px;"> <div class="notice--primary"> <h3> <a href="#which-method-when" class="anchor-heading" aria-labelledby="which-method-when"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Try It Yourself </h3> <p>Compare linear interpolation vs. Random Forest for filling a 24-hour gap in temperature data. Which method captures the daily cycle better?</p> <details> <summary>Solution!</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># The key insight is that linear interpolation can't capture 
# diurnal patterns, while Random Forest (using radiation as 
# a predictor) can.
</span>
<span class="c1"># For a 24-hour gap:
# - Linear interpolation draws a flat line
# - Random Forest predicts warm during day, cool at night
#   (because it learned that high radiation = high temp)
</span>
<span class="c1"># In my experience, Random Forest reduces RMSE by 30-50% 
# compared to linear interpolation for day-long gaps.
</span>
<span class="c1"># But for gaps under 3-6 hours, the methods are often similar
# because temperature hasn't changed much anyway.
</span></code></pre></div> </div> </details> </div> </div><hr /> <h1 id="wrapping-up"> <a href="#wrapping-up" class="anchor-heading" aria-labelledby="wrapping-up"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>Wrapping Up</strong> </h1> <p>We’ve covered a lot of ground here. Let me leave you with the key takeaways:</p> <p><strong>Simple regression</strong> is your starting point. It’s easy to understand, easy to explain, and often good enough for straightforward questions.</p> <p><strong>Multiple regression</strong> lets you account for multiple drivers at once. The coefficients tell you the effect of each variable while controlling for the others.</p> <p><strong>Random Forests</strong> can capture complex patterns that regression misses. They’re particularly good when you don’t know the shape of the relationships in advance.</p> <p><strong>For gap-filling</strong>, match your method to your gap length. Simple interpolation for short gaps, model-based methods for longer ones.</p> <p><strong>Most importantly:</strong> always plot your data, check your assumptions, and validate on independent test data. No amount of fancy statistics can fix bad data or inappropriate models.</p> <p>Good luck with your analyses!</p> <h2 id="where-to-go-from-here"> <a href="#where-to-go-from-here" class="anchor-heading" aria-labelledby="where-to-go-from-here"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Where to Go From Here </h2> <p>If you want to dig deeper:</p> <ul> <li><strong>Generalized Additive Models (GAMs)</strong> let you fit smooth curves instead of straight lines</li> <li><strong>Mixed-effects models</strong> handle hierarchical data (e.g., measurements nested within sites)</li> <li><strong>Gradient Boosting (XGBoost)</strong> often outperforms Random Forests for prediction</li> <li><strong>Time series methods</strong> (ARIMA, etc.) are specifically designed for temporal data</li> </ul> <p>But honestly, you can get surprisingly far with just regression and Random Forests. Master these first before moving on to fancier tools.</p> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
