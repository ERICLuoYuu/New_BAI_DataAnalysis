<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/New_BAI_DataAnalysis/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/New_BAI_DataAnalysis/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li:not(:nth-child(5)) > a, .site-nav > ul.nav-list:first-child > li > ul > li a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(5) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(5) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(5) > ul.nav-list { display: block; } </style> <script src="/New_BAI_DataAnalysis/assets/js/vendor/lunr.min.js"></script> <script src="/New_BAI_DataAnalysis/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>REGRESSION | Data Analysis for Ecologist</title> <meta name="generator" content="Jekyll v3.10.0" /> <meta property="og:title" content="REGRESSION" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="A tutorial for starters learning how to use python to munipulate climate data!" /> <meta property="og:description" content="A tutorial for starters learning how to use python to munipulate climate data!" /> <link rel="canonical" href="https://ericluoyuu.github.io/New_BAI_DataAnalysis/python_3_regression.html" /> <meta property="og:url" content="https://ericluoyuu.github.io/New_BAI_DataAnalysis/python_3_regression.html" /> <meta property="og:site_name" content="Data Analysis for Ecologist" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="REGRESSION" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"A tutorial for starters learning how to use python to munipulate climate data!","headline":"REGRESSION","url":"https://ericluoyuu.github.io/New_BAI_DataAnalysis/python_3_regression.html"}</script> <!-- End Jekyll SEO tag --> </head> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']], displayMath: [ ['$$', '$$'] ], processEscapes: true, processEnvironments: true } }); </script> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"> </script> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/New_BAI_DataAnalysis/" class="site-title lh-tight"> Data Analysis for Ecologist </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/New_BAI_DataAnalysis/" class="nav-list-link">Home</a></li><li class="nav-list-item"><a href="/New_BAI_DataAnalysis/python_0_installation.html" class="nav-list-link">0. INSTALLATION</a></li><li class="nav-list-item"><a href="/New_BAI_DataAnalysis/python_1_basics.html" class="nav-list-link">1. BASICS OF PYTHON</a></li><li class="nav-list-item"><a href="/New_BAI_DataAnalysis/python_2_data_visualization.html" class="nav-list-link">2. DATA HANDLING AND VISUALIZATION</a></li><li class="nav-list-item"><a href="/New_BAI_DataAnalysis/python_3_regression.html" class="nav-list-link">3. REGRESSION</a></li><li class="nav-list-item"><a href="/New_BAI_DataAnalysis/python_4_flux_calculation.html" class="nav-list-link">4. FLUX CALCULATION</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Data Analysis for Ecologist" aria-label="Search Data Analysis for Ecologist" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1 id="regression"> <a href="#regression" class="anchor-heading" aria-labelledby="regression"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>Regression</strong> </h1> <h2 id="table-of-contents"> <a href="#table-of-contents" class="anchor-heading" aria-labelledby="table-of-contents"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Table of Contents </h2> <ul> <li><a href="#chapter-1-whats-regression-all-about">1. What’s Regression All About?</a></li> <li><a href="#chapter-2-simple-linear-regression">2. Simple Linear Regression</a></li> <li><a href="#chapter-3-multiple-regression">3. Multiple Regression</a></li> <li><a href="#chapter-4-machine-learning-with-random-forests">4. Machine Learning with Random Forests</a></li> <li><a href="#chapter-5-filling-gaps-in-time-series">5. Filling Gaps in Time Series</a></li> </ul> <p>Welcome! This tutorial will walk you through regression analysis - one of the most useful tools you’ll encounter for making sense of ecological data. We’ll start from the basics and work our way up to more advanced machine learning methods. Don’t worry if statistics isn’t your strong suit. We’ll take it step by step, and by the end you should feel comfortable applying these techniques to your own data.</p><hr /> <h1 id="1-whats-regression-all-about"> <a href="#1-whats-regression-all-about" class="anchor-heading" aria-labelledby="1-whats-regression-all-about"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>1. What’s Regression All About?</strong> </h1> <h2 id="the-basic-idea"> <a href="#the-basic-idea" class="anchor-heading" aria-labelledby="the-basic-idea"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Basic Idea </h2> <p>Here’s the thing: as ecologists, we’re constantly trying to figure out what drives the patterns we observe. Why are there more species in some places than others? What makes trees grow faster? How does temperature affect animal behavior?</p> <p>Regression gives us a way to quantify these relationships. Instead of just saying “warmer temperatures seem to increase growth,” we can say “for every 1°C increase in temperature, tree ring width increases by 0.15 mm.” That’s powerful stuff.</p> <p>At its core, regression asks: <strong>how does one thing change when another thing changes?</strong></p> <h2 id="a-quick-example"> <a href="#a-quick-example" class="anchor-heading" aria-labelledby="a-quick-example"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> A Quick Example </h2> <p>Let’s say you’re studying tree growth across a temperature gradient. You measure tree ring widths at different sites:</p> <div class="table-wrapper"><table> <thead> <tr> <th>Mean Annual Temperature (°C)</th> <th>Tree Ring Width (mm)</th> </tr> </thead> <tbody> <tr> <td>8</td> <td>1.2</td> </tr> <tr> <td>10</td> <td>1.8</td> </tr> <tr> <td>12</td> <td>2.4</td> </tr> <tr> <td>14</td> <td>2.9</td> </tr> <tr> <td>16</td> <td>3.2</td> </tr> </tbody> </table></div> <p>You can see there’s a pattern - warmer sites have wider rings. But how strong is this relationship? Can we predict growth at a site with 11°C mean temperature? Regression helps us answer these questions.</p> <h2 id="what-can-regression-achieve"> <a href="#what-can-regression-achieve" class="anchor-heading" aria-labelledby="what-can-regression-achieve"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What Can Regression Achieve? </h2> <p>In ecological research, regression is useful for:</p> <p><strong>Making predictions</strong> - You’ve measured carbon flux at 20 sites, but you want to estimate it across the whole landscape. Regression lets you predict values at unmeasured locations based on environmental variables you can get from satellite data.</p> <p><strong>Understanding relationships</strong> - Does nitrogen addition actually increase plant biomass? By how much? Is the effect statistically significant or could it just be noise?</p> <p><strong>Figuring out what matters</strong> - When you have 15 environmental variables that might explain species richness, regression helps you sort out which ones are actually important.</p> <p><strong>Supporting management decisions</strong> - If you know how much habitat area affects population size, you can make informed recommendations about reserve design.</p> <h2 id="terminology"> <a href="#terminology" class="anchor-heading" aria-labelledby="terminology"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Terminology </h2> <p>Before we dive in, let’s get our vocabulary straight. Different fields use different terms for the same things, which can be confusing.</p> <p><strong>Target variable</strong></p> <ul> <li>You can also call it response variable, dependent variable, outcome</li> <li>The variable you’re trying to predict or explain</li> <li>We usually call it <strong>y</strong></li> <li>Examples: species richness, biomass, survival rate, carbon flux</li> </ul> <p><strong>independent variables</strong></p> <ul> <li>Can also be termed predictors, features, independent variables, explanatory variables</li> <li>The variable you use to make predictions or explain target variables</li> <li>We call these <strong>x</strong> (or x₁, x₂, etc. when there are several)</li> <li>Examples: temperature, precipitation, soil pH, elevation</li> </ul> <p><strong>The model:</strong></p> <ul> <li>This is the mathematical equation that describes how x relates to y</li> <li>General form: y = f(x) + error</li> <li>The “error” part is important - it acknowledges that our model won’t be perfect</li> </ul> <p><strong>Coefficients:</strong></p> <ul> <li>These are the numbers in our model that define the relationship</li> <li>In a simple model like y = 3 + 2x, the “3” is the intercept and “2” is the slope</li> <li>We estimate these from our data</li> </ul> <p><strong>Residuals:</strong></p> <ul> <li>The difference between what we observed and what our model predicted</li> <li>Small residuals = good model fit</li> <li>Patterns in residuals = something’s wrong with our model</li> </ul> <h2 id="how-does-regression-actually-work"> <a href="#how-does-regression-actually-work" class="anchor-heading" aria-labelledby="how-does-regression-actually-work"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How Does Regression Actually Work? </h2> <p>The basic process goes like this:</p> <ol> <li> <p><strong>Choose a model type.</strong> Are you assuming a straight line relationship? A curve? Multiple predictors?</p> </li> <li> <p><strong>Fit the model to your data.</strong> This means finding the coefficient values that make your predictions as close to the observations as possible.</p> </li> <li> <p><strong>Check if it worked.</strong> Look at how well the model fits, whether the assumptions are met, and whether the results make ecological sense.</p> </li> </ol> <p>The most common approach for step 2 is called “least squares” - we find the coefficients that minimize the sum of squared differences between observed and predicted values. We square the differences so that positive and negative errors don’t cancel out.</p> <h2 id="evaluating-your-model"> <a href="#evaluating-your-model" class="anchor-heading" aria-labelledby="evaluating-your-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Evaluating Your Model </h2> <p>How do you know if your model is any good? A few key metrics:</p> <p><strong>R² (R-squared)</strong>: This tells you what fraction of the variation in your data is explained by the model. An R² of 0.7 means your model explains 70% of the variance. What’s “good” depends entirely on your system - in controlled experiments 0.9 might be expected, while in field ecology 0.3 might be excellent.</p> <div>$$ R^2 = 1 - \frac{SS_{res}}{SS_{tot}} = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2} $$</div> <p>Where:</p> <p>$y_i$ is the observed value</p> <p>$\hat{y}_i$ is the predicted value</p> <p>$\bar{y}$ is the mean of observed values</p> <p>$SS_{res}$ is the sum of squared residuals</p> <p>$SS_{tot}$ is the total sum of squares</p> <p><strong>RMSE (Root Mean Square Error)</strong>: This is the average size of your prediction errors, in the same units as your response variable. An RMSE of 2.5°C for a temperature model means your predictions are typically off by about 2.5 degrees.</p> <div>$$ RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2} $$</div> <p><strong>MAE (Mean Absolute Error)</strong>: Similar to RMSE but less sensitive to outliers. Useful when you have some weird extreme values in your data.</p> <div>$$ MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i| $$</div> <p>The difference between RMSE and MAE? RMSE penalizes large errors more heavily because of the squaring. If you have a few really bad predictions, RMSE will be much higher than MAE. This can be useful for detecting outliers or problematic predictions.</p><hr /> <h1 id="chapter-2-simple-linear-regression"> <a href="#chapter-2-simple-linear-regression" class="anchor-heading" aria-labelledby="chapter-2-simple-linear-regression"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>Chapter 2: Simple Linear Regression</strong> </h1> <p>Alright, let’s actually do some regression. We’ll start with the simplest case: one predictor, one response, straight line relationship.</p> <h2 id="the-model"> <a href="#the-model" class="anchor-heading" aria-labelledby="the-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Model </h2> <p>Simple linear regression fits this equation:</p> <p><strong>y = β₀ + β₁x</strong></p> <p>Where:</p> <ul> <li>β₀ is the intercept (value of y when x is zero)</li> <li>β₁ is the slope (how much y changes for each unit increase in x)</li> </ul> <p>That’s it. We’re just fitting a line through our data points.</p> <h2 id="lets-try-it-penguin-body-mass-and-flipper-length"> <a href="#lets-try-it-penguin-body-mass-and-flipper-length" class="anchor-heading" aria-labelledby="lets-try-it-penguin-body-mass-and-flipper-length"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Let’s Try It: Penguin Body Mass and Flipper Length </h2> <p>We’ll use the Palmer Penguins dataset - real measurements collected by Dr. Kristen Gorman at Palmer Station, Antarctica.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="n">px</span>
<span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="n">go</span>

<span class="c1"># Load the penguins dataset
# You can install it with: pip install palmerpenguins
</span><span class="kn">from</span> <span class="nn">palmerpenguins</span> <span class="kn">import</span> <span class="n">load_penguins</span>
<span class="n">penguins</span> <span class="o">=</span> <span class="n">load_penguins</span><span class="p">()</span>

<span class="c1"># Take a look at what we have
</span><span class="k">print</span><span class="p">(</span><span class="s">"Dataset shape:"</span><span class="p">,</span> <span class="n">penguins</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">First few rows:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">penguins</span><span class="p">.</span><span class="n">head</span><span class="p">())</span>

<span class="c1"># Check for missing values and drop them for now
</span><span class="n">penguins_clean</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s">'flipper_length_mm'</span><span class="p">,</span> <span class="s">'body_mass_g'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Complete cases: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">penguins_clean</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <p>Now let’s explore the relationship between flipper length and body mass:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Quick visualization
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">penguins_clean</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'flipper_length_mm'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'body_mass_g'</span><span class="p">,</span>
                 <span class="n">color</span><span class="o">=</span><span class="s">'species'</span><span class="p">,</span>
                 <span class="n">title</span><span class="o">=</span><span class="s">'Penguin Body Mass vs Flipper Length'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="s">'simple_white'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <p>You’ll see there’s clearly a positive relationship - longer flippers go with heavier birds. Let’s quantify it.</p> <h3 id="fitting-the-regression"> <a href="#fitting-the-regression" class="anchor-heading" aria-labelledby="fitting-the-regression"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Fitting the Regression </h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># Prepare the data
</span><span class="n">X</span> <span class="o">=</span> <span class="n">penguins_clean</span><span class="p">[[</span><span class="s">'flipper_length_mm'</span><span class="p">]].</span><span class="n">values</span>  <span class="c1"># sklearn wants 2D array
</span><span class="n">y</span> <span class="o">=</span> <span class="n">penguins_clean</span><span class="p">[</span><span class="s">'body_mass_g'</span><span class="p">].</span><span class="n">values</span>

<span class="c1"># Fit the model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Slope: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> g per mm"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Intercept: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">intercept_</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> g"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"R-squared: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="visualizing-the-fit"> <a href="#visualizing-the-fit" class="anchor-heading" aria-labelledby="visualizing-the-fit"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Visualizing the Fit </h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Get predictions for the regression line
</span><span class="n">X_line</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">penguins_clean</span><span class="p">[</span><span class="s">'flipper_length_mm'</span><span class="p">].</span><span class="nb">min</span><span class="p">(),</span> 
                     <span class="n">penguins_clean</span><span class="p">[</span><span class="s">'flipper_length_mm'</span><span class="p">].</span><span class="nb">max</span><span class="p">(),</span> <span class="mi">100</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_line</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_line</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="n">Figure</span><span class="p">()</span>

<span class="c1"># Data points
</span><span class="n">fig</span><span class="p">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="n">Scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">penguins_clean</span><span class="p">[</span><span class="s">'flipper_length_mm'</span><span class="p">],</span> 
    <span class="n">y</span><span class="o">=</span><span class="n">penguins_clean</span><span class="p">[</span><span class="s">'body_mass_g'</span><span class="p">],</span>
    <span class="n">mode</span><span class="o">=</span><span class="s">'markers'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'Observations'</span><span class="p">,</span>
    <span class="n">marker</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">opacity</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="p">))</span>

<span class="c1"># Regression line
</span><span class="n">fig</span><span class="p">.</span><span class="n">add_trace</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="n">Scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">X_line</span><span class="p">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">y</span><span class="o">=</span><span class="n">y_line</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s">'lines'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'Regression line'</span><span class="p">,</span>
    <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="p">))</span>

<span class="n">fig</span><span class="p">.</span><span class="n">update_layout</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s">'Penguin Body Mass vs Flipper Length'</span><span class="p">,</span>
    <span class="n">xaxis_title</span><span class="o">=</span><span class="s">'Flipper Length (mm)'</span><span class="p">,</span>
    <span class="n">yaxis_title</span><span class="o">=</span><span class="s">'Body Mass (g)'</span><span class="p">,</span>
    <span class="n">template</span><span class="o">=</span><span class="s">'simple_white'</span>
<span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <h2 id="what-do-these-numbers-mean"> <a href="#what-do-these-numbers-mean" class="anchor-heading" aria-labelledby="what-do-these-numbers-mean"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What Do These Numbers Mean? </h2> <p>With real data, you should get something like:</p> <ul> <li><strong>Slope ≈ 49.7 g/mm</strong>: For every 1 mm increase in flipper length, body mass increases by about 50 grams</li> <li><strong>Intercept ≈ -5781 g</strong>: This would be the predicted mass at flipper length = 0, which makes no biological sense (negative mass!), but it’s needed mathematically to position the line</li> <li><strong>R² ≈ 0.76</strong>: Flipper length explains about 76% of the variation in body mass</li> </ul> <p>That R² is pretty good for biological data! It means if you only know a penguin’s flipper length, you can predict its mass reasonably well.</p> <h3 id="making-predictions"> <a href="#making-predictions" class="anchor-heading" aria-labelledby="making-predictions"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Making Predictions </h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># What's the predicted mass for a penguin with 200mm flippers?
</span><span class="n">new_flipper</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">200</span><span class="p">]])</span>
<span class="n">predicted_mass</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_flipper</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Predicted mass for 200mm flipper: </span><span class="si">{</span><span class="n">predicted_mass</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s"> g"</span><span class="p">)</span>

<span class="c1"># What about 180mm?
</span><span class="n">new_flipper</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">180</span><span class="p">]])</span>
<span class="n">predicted_mass</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_flipper</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Predicted mass for 180mm flipper: </span><span class="si">{</span><span class="n">predicted_mass</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s"> g"</span><span class="p">)</span>
</code></pre></div></div> <div style="background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin-bottom: 5px;"> <div class="notice--primary"> <h3> <a href="#making-predictions" class="anchor-heading" aria-labelledby="making-predictions"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Try It Yourself </h3> <p>Using the Palmer Penguins dataset, fit a simple regression predicting bill length from bill depth. What do you find? Is the relationship positive or negative? How does R² compare to the flipper-mass relationship?</p> <details> <summary>Solution!</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">palmerpenguins</span> <span class="kn">import</span> <span class="n">load_penguins</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">penguins</span> <span class="o">=</span> <span class="n">load_penguins</span><span class="p">().</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s">'bill_length_mm'</span><span class="p">,</span> <span class="s">'bill_depth_mm'</span><span class="p">])</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[[</span><span class="s">'bill_depth_mm'</span><span class="p">]].</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s">'bill_length_mm'</span><span class="p">].</span><span class="n">values</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Slope: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Intercept: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">intercept_</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"R-squared: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Surprise! You'll find a NEGATIVE relationship and very low R²
# This is Simpson's paradox - when you combine the species,
# the overall trend is negative, but within each species 
# the relationship is positive. This is because Gentoo penguins
# have long bills but shallow depth, while Adelie have 
# shorter bills but deeper depth.
</span>
<span class="c1"># Try it by species:
</span><span class="k">for</span> <span class="n">species</span> <span class="ow">in</span> <span class="n">penguins</span><span class="p">[</span><span class="s">'species'</span><span class="p">].</span><span class="n">unique</span><span class="p">():</span>
    <span class="n">subset</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="n">penguins</span><span class="p">[</span><span class="s">'species'</span><span class="p">]</span> <span class="o">==</span> <span class="n">species</span><span class="p">]</span>
    <span class="n">X_sp</span> <span class="o">=</span> <span class="n">subset</span><span class="p">[[</span><span class="s">'bill_depth_mm'</span><span class="p">]].</span><span class="n">values</span>
    <span class="n">y_sp</span> <span class="o">=</span> <span class="n">subset</span><span class="p">[</span><span class="s">'bill_length_mm'</span><span class="p">].</span><span class="n">values</span>
    <span class="n">model_sp</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sp</span><span class="p">,</span> <span class="n">y_sp</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">species</span><span class="si">}</span><span class="s">: slope = </span><span class="si">{</span><span class="n">model_sp</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">, R² = </span><span class="si">{</span><span class="n">model_sp</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_sp</span><span class="p">,</span> <span class="n">y_sp</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div> </div> </details> </div> </div> <h2 id="a-word-of-caution"> <a href="#a-word-of-caution" class="anchor-heading" aria-labelledby="a-word-of-caution"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> A Word of Caution </h2> <p>The exercise above reveals something important: simple regression can be misleading when you have groups in your data. The overall flipper-mass relationship also differs among species - Gentoo penguins are bigger than Adelie and Chinstrap.</p> <p>This is one reason we need multiple regression - to account for additional factors that might be confounding our results.</p><hr /> <h1 id="chapter-3-multiple-regression"> <a href="#chapter-3-multiple-regression" class="anchor-heading" aria-labelledby="chapter-3-multiple-regression"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>Chapter 3: Multiple Regression</strong> </h1> <p>In the real world, ecological responses depend on many factors simultaneously. Multiple regression lets us include all of them in one model.</p> <h2 id="why-go-multiple"> <a href="#why-go-multiple" class="anchor-heading" aria-labelledby="why-go-multiple"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Why Go Multiple? </h2> <p>Looking at the penguin data, body mass depends on more than just flipper length:</p> <ul> <li>Species differ in overall body size</li> <li>Males are larger than females</li> <li>Bill dimensions correlate with mass too</li> </ul> <p>If we only model mass against flipper length, we’re missing important information. Multiple regression lets us ask: “what’s the effect of flipper length, <em>after accounting for</em> species and sex?”</p> <h2 id="the-model-1"> <a href="#the-model-1" class="anchor-heading" aria-labelledby="the-model-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Model </h2> <p>We extend our simple model to include multiple predictors:</p> <p><strong>y = β₀ + β₁x₁ + β₂x₂ + β₃x₃ + …</strong></p> <p>Each coefficient now tells us the effect of that variable <em>while holding the others constant</em>. This is crucial for interpretation.</p> <h2 id="example-predicting-penguin-body-mass"> <a href="#example-predicting-penguin-body-mass" class="anchor-heading" aria-labelledby="example-predicting-penguin-body-mass"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Example: Predicting Penguin Body Mass </h2> <p>Let’s build a more complete model for penguin body mass.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">palmerpenguins</span> <span class="kn">import</span> <span class="n">load_penguins</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="n">metrics</span>

<span class="c1"># Load and prepare data
</span><span class="n">penguins</span> <span class="o">=</span> <span class="n">load_penguins</span><span class="p">().</span><span class="n">dropna</span><span class="p">()</span>

<span class="c1"># Encode categorical variables (species and sex) as numbers
</span><span class="n">le_species</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le_sex</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">penguins</span><span class="p">[</span><span class="s">'species_code'</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_species</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s">'species'</span><span class="p">])</span>
<span class="n">penguins</span><span class="p">[</span><span class="s">'sex_code'</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_sex</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s">'sex'</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Species encoding:"</span><span class="p">,</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">le_species</span><span class="p">.</span><span class="n">classes_</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">le_species</span><span class="p">.</span><span class="n">classes_</span><span class="p">)))))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Sex encoding:"</span><span class="p">,</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">le_sex</span><span class="p">.</span><span class="n">classes_</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">le_sex</span><span class="p">.</span><span class="n">classes_</span><span class="p">)))))</span>

<span class="c1"># Check what we have
</span><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Dataset: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">penguins</span><span class="p">)</span><span class="si">}</span><span class="s"> penguins"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">penguins</span><span class="p">[[</span><span class="s">'species'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">,</span> <span class="s">'flipper_length_mm'</span><span class="p">,</span> <span class="s">'bill_length_mm'</span><span class="p">,</span> 
                <span class="s">'bill_depth_mm'</span><span class="p">,</span> <span class="s">'body_mass_g'</span><span class="p">]].</span><span class="n">head</span><span class="p">())</span>
</code></pre></div></div> <h3 id="check-correlations-first"> <a href="#check-correlations-first" class="anchor-heading" aria-labelledby="check-correlations-first"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Check Correlations First </h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Which variables correlate with body mass?
</span><span class="n">numeric_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">'flipper_length_mm'</span><span class="p">,</span> <span class="s">'bill_length_mm'</span><span class="p">,</span> <span class="s">'bill_depth_mm'</span><span class="p">,</span> 
                <span class="s">'body_mass_g'</span><span class="p">,</span> <span class="s">'species_code'</span><span class="p">,</span> <span class="s">'sex_code'</span><span class="p">]</span>
                
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Correlations with body mass:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="n">numeric_cols</span><span class="p">].</span><span class="n">corr</span><span class="p">()[</span><span class="s">'body_mass_g'</span><span class="p">].</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
</code></pre></div></div> <h3 id="fitting-the-multiple-regression"> <a href="#fitting-the-multiple-regression" class="anchor-heading" aria-labelledby="fitting-the-multiple-regression"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Fitting the Multiple Regression </h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Prepare features and target
</span><span class="n">X</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[[</span><span class="s">'flipper_length_mm'</span><span class="p">,</span> <span class="s">'bill_length_mm'</span><span class="p">,</span> <span class="s">'bill_depth_mm'</span><span class="p">,</span> 
              <span class="s">'species_code'</span><span class="p">,</span> <span class="s">'sex_code'</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s">'body_mass_g'</span><span class="p">]</span>

<span class="c1"># Split into training and test sets
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Training set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="si">}</span><span class="s"> penguins"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Test set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="si">}</span><span class="s"> penguins"</span><span class="p">)</span>

<span class="c1"># Fit the model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Look at coefficients
</span><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Model coefficients:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Intercept: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">intercept_</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">coef</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <h2 id="interpreting-the-results"> <a href="#interpreting-the-results" class="anchor-heading" aria-labelledby="interpreting-the-results"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Interpreting the Results </h2> <p>What do these coefficients actually mean?</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"""
Interpreting the coefficients:

flipper_length_mm: Each additional mm of flipper length adds about 
  17g to body mass, after controlling for other variables. Note this 
  is smaller than in simple regression (~50g) because some of that 
  effect was actually due to species differences.

bill_length_mm: Longer bills are associated with slightly higher mass,
  holding other variables constant.

bill_depth_mm: Deeper bills are associated with higher mass. This makes
  sense - it's a measure of overall head size.

species_code: The coefficient shows average difference between species
  (encoded as 0, 1, 2). Interpretation is tricky with encoded categories.

sex_code: Males (coded as 1) are heavier than females (coded as 0) by
  about this many grams, controlling for body measurements.
"""</span><span class="p">)</span>
</code></pre></div></div> <h3 id="how-good-is-our-model"> <a href="#how-good-is-our-model" class="anchor-heading" aria-labelledby="how-good-is-our-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How Good Is Our Model? </h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Predict on test data
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Calculate metrics
</span><span class="n">r2</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="n">mae</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"R-squared: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"RMSE: </span><span class="si">{</span><span class="n">rmse</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s"> g"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"MAE: </span><span class="si">{</span><span class="n">mae</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s"> g"</span><span class="p">)</span>

<span class="c1"># Plot predicted vs observed
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
                 <span class="n">labels</span><span class="o">=</span><span class="p">{</span><span class="s">'x'</span><span class="p">:</span> <span class="s">'Observed Mass (g)'</span><span class="p">,</span> <span class="s">'y'</span><span class="p">:</span> <span class="s">'Predicted Mass (g)'</span><span class="p">})</span>
<span class="n">fig</span><span class="p">.</span><span class="n">add_scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="n">y_test</span><span class="p">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">y_test</span><span class="p">.</span><span class="nb">max</span><span class="p">()],</span> 
                <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="n">y_test</span><span class="p">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">y_test</span><span class="p">.</span><span class="nb">max</span><span class="p">()],</span>
                <span class="n">mode</span><span class="o">=</span><span class="s">'lines'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'1:1 line'</span><span class="p">,</span>
                <span class="n">line</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">dash</span><span class="o">=</span><span class="s">'dash'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">))</span>
<span class="n">fig</span><span class="p">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="s">'simple_white'</span><span class="p">,</span>
                  <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s">'Multiple Regression: R² = </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <h2 id="does-adding-variables-help"> <a href="#does-adding-variables-help" class="anchor-heading" aria-labelledby="does-adding-variables-help"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Does Adding Variables Help? </h2> <p>Let’s compare models with different numbers of predictors:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Just flipper length
</span><span class="n">m1</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s">'flipper_length_mm'</span><span class="p">]],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Model'</span><span class="p">:</span> <span class="s">'Flipper only'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">m1</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="s">'flipper_length_mm'</span><span class="p">]],</span> <span class="n">y_test</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># Flipper + species
</span><span class="n">m2</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s">'flipper_length_mm'</span><span class="p">,</span> <span class="s">'species_code'</span><span class="p">]],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Model'</span><span class="p">:</span> <span class="s">'Flipper + Species'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">m2</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="s">'flipper_length_mm'</span><span class="p">,</span> <span class="s">'species_code'</span><span class="p">]],</span> <span class="n">y_test</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># Flipper + species + sex
</span><span class="n">m3</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s">'flipper_length_mm'</span><span class="p">,</span> <span class="s">'species_code'</span><span class="p">,</span> <span class="s">'sex_code'</span><span class="p">]],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Model'</span><span class="p">:</span> <span class="s">'Flipper + Species + Sex'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">m3</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="s">'flipper_length_mm'</span><span class="p">,</span> <span class="s">'species_code'</span><span class="p">,</span> <span class="s">'sex_code'</span><span class="p">]],</span> <span class="n">y_test</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># All predictors
</span><span class="n">m4</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Model'</span><span class="p">:</span> <span class="s">'All predictors'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">m4</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="p">})</span>

<span class="k">print</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">))</span>
</code></pre></div></div> <p>You should see R² improve as you add relevant predictors - species and sex both contribute meaningful information about body mass.</p> <div style="background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin-bottom: 5px;"> <div class="notice--primary"> <h3> <a href="#does-adding-variables-help" class="anchor-heading" aria-labelledby="does-adding-variables-help"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Try It Yourself </h3> <p>Build a multiple regression model predicting bill length from bill depth, flipper length, species, and sex. Which predictors have the strongest effects? Does the bill depth coefficient change from the simple regression?</p> <details> <summary>Solution!</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">palmerpenguins</span> <span class="kn">import</span> <span class="n">load_penguins</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="n">penguins</span> <span class="o">=</span> <span class="n">load_penguins</span><span class="p">().</span><span class="n">dropna</span><span class="p">()</span>

<span class="c1"># Encode categoricals
</span><span class="n">le_species</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le_sex</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">penguins</span><span class="p">[</span><span class="s">'species_code'</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_species</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s">'species'</span><span class="p">])</span>
<span class="n">penguins</span><span class="p">[</span><span class="s">'sex_code'</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_sex</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">penguins</span><span class="p">[</span><span class="s">'sex'</span><span class="p">])</span>

<span class="c1"># Prepare data
</span><span class="n">X</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[[</span><span class="s">'bill_depth_mm'</span><span class="p">,</span> <span class="s">'flipper_length_mm'</span><span class="p">,</span> <span class="s">'species_code'</span><span class="p">,</span> <span class="s">'sex_code'</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s">'bill_length_mm'</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Full model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"R²: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Coefficients:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">coef</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">coef</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Compare to simple regression
</span><span class="n">simple</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">simple</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">penguins</span><span class="p">[[</span><span class="s">'bill_depth_mm'</span><span class="p">]],</span> <span class="n">penguins</span><span class="p">[</span><span class="s">'bill_length_mm'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Simple regression bill_depth coefficient: </span><span class="si">{</span><span class="n">simple</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Multiple regression bill_depth coefficient: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># The bill_depth coefficient changes dramatically - in simple regression
# it's negative (Simpson's paradox), but in multiple regression 
# controlling for species, it becomes positive as expected.
</span></code></pre></div> </div> </details> </div> </div> <h2 id="limitations"> <a href="#limitations" class="anchor-heading" aria-labelledby="limitations"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Limitations </h2> <p>Multiple regression is powerful but has some important limitations:</p> <p><strong>It assumes linear relationships.</strong> If the relationship between flipper length and mass is curved (it often is at extremes), a linear model won’t capture that properly.</p> <p><strong>It assumes additive effects.</strong> The model says the effect of flipper length is the same for all species. In reality, species might differ in their flipper-mass scaling.</p> <p><strong>Categorical encoding matters.</strong> We used simple numeric codes for species, but this assumes equal “distances” between categories, which doesn’t make biological sense.</p> <p>These limitations bring us to machine learning approaches, which can handle more complexity.</p><hr /> <h1 id="chapter-4-machine-learning-with-random-forests"> <a href="#chapter-4-machine-learning-with-random-forests" class="anchor-heading" aria-labelledby="chapter-4-machine-learning-with-random-forests"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>Chapter 4: Machine Learning with Random Forests</strong> </h1> <p>Alright, now we’re getting to the fun stuff. Machine learning sounds fancy, but the basic idea is simple: let the algorithm figure out the patterns in your data, rather than you specifying them in advance.</p> <h2 id="why-machine-learning"> <a href="#why-machine-learning" class="anchor-heading" aria-labelledby="why-machine-learning"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Why Machine Learning? </h2> <p>Ecological relationships are often messy:</p> <ul> <li>Relationships might be non-linear</li> <li>Effects of one variable depend on another (interactions)</li> <li>There might be thresholds we didn’t anticipate</li> </ul> <p>Machine learning algorithms can discover these patterns automatically. You don’t have to know the shape of the relationship beforehand.</p> <h2 id="decision-trees-the-building-block"> <a href="#decision-trees-the-building-block" class="anchor-heading" aria-labelledby="decision-trees-the-building-block"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Decision Trees: The Building Block </h2> <p>Before we get to Random Forests, we need to understand decision trees. They’re intuitive once you see how they work.</p> <p>A decision tree is basically a flowchart of questions:</p> <ul> <li>Is flipper length &gt; 206mm? <ul> <li>Yes → Probably a Gentoo, predict ~5000g</li> <li>No → Is bill depth &gt; 18mm? <ul> <li>Yes → Probably Adelie, predict ~3700g</li> <li>No → Probably Chinstrap, predict ~3500g</li> </ul> </li> </ul> </li> </ul> <p>The algorithm figures out which questions to ask and what thresholds to use by looking at your data.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span><span class="p">,</span> <span class="n">plot_tree</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Using our penguin data
</span><span class="n">X</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[[</span><span class="s">'flipper_length_mm'</span><span class="p">,</span> <span class="s">'bill_length_mm'</span><span class="p">,</span> <span class="s">'bill_depth_mm'</span><span class="p">,</span> 
              <span class="s">'species_code'</span><span class="p">,</span> <span class="s">'sex_code'</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s">'body_mass_g'</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Fit a simple tree
</span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tree</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Visualize it
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Decision Tree for Penguin Body Mass'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Decision Tree R²: </span><span class="si">{</span><span class="n">tree</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <p>Decision trees are easy to interpret - you can literally see the rules. But they have a problem: they tend to overfit. A deep tree can memorize the training data perfectly but fail miserably on new data.</p> <h2 id="random-forests-many-trees-are-better-than-one"> <a href="#random-forests-many-trees-are-better-than-one" class="anchor-heading" aria-labelledby="random-forests-many-trees-are-better-than-one"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Random Forests: Many Trees Are Better Than One </h2> <p>Random Forests solve the overfitting problem by building many trees and averaging their predictions. Each tree is a bit different because:</p> <ol> <li>Each tree is trained on a random subset of the data (with replacement)</li> <li>At each split, only a random subset of variables is considered</li> </ol> <p>This randomness means individual trees might make mistakes, but averaging over hundreds of trees gives robust predictions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="c1"># Fit a random forest
</span><span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>    <span class="c1"># number of trees
</span>    <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>        <span class="c1"># how deep each tree can go
</span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
<span class="n">rf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluate
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Random Forest R²: </span><span class="si">{</span><span class="n">metrics</span><span class="p">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Random Forest RMSE: </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s"> g"</span><span class="p">)</span>
</code></pre></div></div> <h2 id="comparing-all-our-methods"> <a href="#comparing-all-our-methods" class="anchor-heading" aria-labelledby="comparing-all-our-methods"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Comparing All Our Methods </h2> <p>Let’s see how everything stacks up on the penguin data:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Simple regression
</span><span class="n">simple</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">simple</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s">'flipper_length_mm'</span><span class="p">]],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">simple</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="s">'flipper_length_mm'</span><span class="p">]])</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Method'</span><span class="p">:</span> <span class="s">'Simple regression'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">metrics</span><span class="p">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">),</span>
    <span class="s">'RMSE'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="p">})</span>

<span class="c1"># Multiple regression
</span><span class="n">multi</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">multi</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">multi</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Method'</span><span class="p">:</span> <span class="s">'Multiple regression'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">metrics</span><span class="p">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">),</span>
    <span class="s">'RMSE'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="p">})</span>

<span class="c1"># Decision tree
</span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tree</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">tree</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Method'</span><span class="p">:</span> <span class="s">'Decision tree'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">metrics</span><span class="p">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">),</span>
    <span class="s">'RMSE'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="p">})</span>

<span class="c1"># Random forest
</span><span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">rf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
    <span class="s">'Method'</span><span class="p">:</span> <span class="s">'Random forest'</span><span class="p">,</span>
    <span class="s">'R²'</span><span class="p">:</span> <span class="n">metrics</span><span class="p">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">),</span>
    <span class="s">'RMSE'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
<span class="p">})</span>

<span class="k">print</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">).</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
</code></pre></div></div> <h2 id="whats-driving-the-patterns"> <a href="#whats-driving-the-patterns" class="anchor-heading" aria-labelledby="whats-driving-the-patterns"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What’s Driving the Patterns? </h2> <p>One of the nicest things about Random Forests is that they tell you which variables matter most:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">importance</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s">'Variable'</span><span class="p">:</span> <span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span>
    <span class="s">'Importance'</span><span class="p">:</span> <span class="n">rf</span><span class="p">.</span><span class="n">feature_importances_</span>
<span class="p">}).</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'Importance'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Variable importance:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">importance</span><span class="p">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>

<span class="c1"># Plot it
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">importance</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Importance'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'Variable'</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s">'h'</span><span class="p">,</span>
             <span class="n">title</span><span class="o">=</span><span class="s">'What drives penguin body mass?'</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="s">'simple_white'</span><span class="p">,</span> <span class="n">yaxis</span><span class="o">=</span><span class="p">{</span><span class="s">'categoryorder'</span><span class="p">:</span> <span class="s">'total ascending'</span><span class="p">})</span>
<span class="n">fig</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div> <p>For the penguin data, you’ll probably find that sex and flipper length are the most important predictors - which makes biological sense!</p> <div style="background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin-bottom: 5px;"> <div class="notice--primary"> <h3> <a href="#whats-driving-the-patterns" class="anchor-heading" aria-labelledby="whats-driving-the-patterns"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Try It Yourself </h3> <p>Use Random Forest to predict penguin species (as a classification problem) from the morphological measurements. Which measurements are most useful for distinguishing species?</p> <p><strong>Hint:</strong> Use <code>RandomForestClassifier</code> instead of <code>RandomForestRegressor</code></p> <details> <summary>Solution!</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>

<span class="n">penguins</span> <span class="o">=</span> <span class="n">load_penguins</span><span class="p">().</span><span class="n">dropna</span><span class="p">()</span>

<span class="c1"># Prepare data - predict species from measurements
</span><span class="n">X</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[[</span><span class="s">'bill_length_mm'</span><span class="p">,</span> <span class="s">'bill_depth_mm'</span><span class="p">,</span> <span class="s">'flipper_length_mm'</span><span class="p">,</span> <span class="s">'body_mass_g'</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">penguins</span><span class="p">[</span><span class="s">'species'</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Fit classifier
</span><span class="n">rf_clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rf_clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluate
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Accuracy: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Classification Report:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="c1"># Feature importance
</span><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Feature importance for species classification:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">imp</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">rf_clf</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">),</span> 
                        <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">imp</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Bill length and bill depth are typically most important -
# they differ most clearly between species
</span></code></pre></div> </div> </details> </div> </div><hr /> <h1 id="5-gap-filling-in-time-series"> <a href="#5-gap-filling-in-time-series" class="anchor-heading" aria-labelledby="5-gap-filling-in-time-series"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>5. Gap-filling in Time Series</strong> </h1> <p>Now let’s apply what we’ve learned to a practical problem: dealing with missing data in ecological time series.</p> <h2 id="the-problem"> <a href="#the-problem" class="anchor-heading" aria-labelledby="the-problem"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Problem </h2> <p>If you’ve worked with field data, you know this frustration. Your sensor died for a week. The battery ran out during the coldest part of winter. Someone accidentally unplugged the datalogger.</p> <p>Missing data is annoying because:</p> <ul> <li>You can’t calculate annual totals or means</li> <li>It messes up time series analyses</li> <li>Some statistical methods can’t handle NaN values</li> </ul> <h2 id="loading-messy-data"> <a href="#loading-messy-data" class="anchor-heading" aria-labelledby="loading-messy-data"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Loading Messy Data </h2> <p>Real data often has placeholder values instead of proper missing data markers. Let’s see an example:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Load meteorological data
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="s">'./dwd_ahaus_1996_2023_missing_placeholders.parquet'</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"data_time"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"data_time"</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Temperature range: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">].</span><span class="nb">min</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s"> to </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <p>If you see -999.99 as the minimum, that’s a placeholder for missing data - not an actual temperature! We need to fix this:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Replace placeholder with NaN
</span><span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">"tair_2m_mean"</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mf">999.99</span><span class="p">,</span> <span class="s">"tair_2m_mean"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">NaN</span>

<span class="c1"># Now check
</span><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Missing values: </span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">].</span><span class="n">isna</span><span class="p">().</span><span class="nb">sum</span><span class="p">()</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <h2 id="method-1-linear-interpolation"> <a href="#method-1-linear-interpolation" class="anchor-heading" aria-labelledby="method-1-linear-interpolation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Method 1: Linear Interpolation </h2> <p>The simplest approach - just draw a straight line between known values:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Pandas makes this easy
</span><span class="n">df</span><span class="p">[</span><span class="s">'temp_interp'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">].</span><span class="n">interpolate</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">'linear'</span><span class="p">)</span>
</code></pre></div></div> <p>This works fine for short gaps. If temperature was 10°C at noon and 14°C at 2pm, it’s reasonable to guess 12°C at 1pm.</p> <p>But it fails badly for longer gaps. It can’t capture the daily temperature cycle - if you have a 24-hour gap, linear interpolation will give you a flat line right through where the daily max and min should be.</p> <h2 id="method-2-regression-based-gap-filling"> <a href="#method-2-regression-based-gap-filling" class="anchor-heading" aria-labelledby="method-2-regression-based-gap-filling"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Method 2: Regression-Based Gap Filling </h2> <p>If we have other variables that were measured continuously, we can use them to estimate the missing temperatures:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># Solar radiation and humidity are often available when temperature fails
# (different sensors)
</span><span class="n">predictors</span> <span class="o">=</span> <span class="p">[</span><span class="s">'SWIN'</span><span class="p">,</span> <span class="s">'rH'</span><span class="p">]</span>

<span class="c1"># Get data where everything is present (for training)
</span><span class="n">df_complete</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'data_time'</span><span class="p">,</span> <span class="s">'SWIN'</span><span class="p">,</span> <span class="s">'rH'</span><span class="p">,</span> <span class="s">'tair_2m_mean'</span><span class="p">]].</span><span class="n">dropna</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_complete</span><span class="p">[</span><span class="n">predictors</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_complete</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">]</span>

<span class="c1"># Fit model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Gap-filling model R²: </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <p>Then we can predict temperature wherever we have radiation and humidity data:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Find rows where temp is missing but predictors exist
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">].</span><span class="n">isna</span><span class="p">()</span> <span class="o">&amp;</span> <span class="n">df</span><span class="p">[</span><span class="s">'SWIN'</span><span class="p">].</span><span class="n">notna</span><span class="p">()</span> <span class="o">&amp;</span> <span class="n">df</span><span class="p">[</span><span class="s">'rH'</span><span class="p">].</span><span class="n">notna</span><span class="p">()</span>
<span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="s">'temp_regression'</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="n">predictors</span><span class="p">])</span>
</code></pre></div></div> <h2 id="method-3-random-forest-gap-filling"> <a href="#method-3-random-forest-gap-filling" class="anchor-heading" aria-labelledby="method-3-random-forest-gap-filling"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Method 3: Random Forest Gap Filling </h2> <p>For better accuracy, especially with complex patterns, Random Forest often wins:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="c1"># Use more predictors
</span><span class="n">all_predictors</span> <span class="o">=</span> <span class="p">[</span><span class="s">'SWIN'</span><span class="p">,</span> <span class="s">'rH'</span><span class="p">,</span> <span class="s">'pressure_air'</span><span class="p">,</span> <span class="s">'wind_speed'</span><span class="p">,</span> <span class="s">'precipitation'</span><span class="p">]</span>
<span class="n">df_complete</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">all_predictors</span> <span class="o">+</span> <span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">]].</span><span class="n">dropna</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_complete</span><span class="p">[</span><span class="n">all_predictors</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_complete</span><span class="p">[</span><span class="s">'tair_2m_mean'</span><span class="p">]</span>

<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Random Forest R²: </span><span class="si">{</span><span class="n">rf</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Check which predictors matter most for estimating temperature
</span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">imp</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">all_predictors</span><span class="p">,</span> <span class="n">rf</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">),</span> 
                        <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">imp</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <h2 id="which-method-when"> <a href="#which-method-when" class="anchor-heading" aria-labelledby="which-method-when"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Which Method When? </h2> <p>After working with a lot of gap-filled data, here’s what I’ve found:</p> <p><strong>Short gaps (a few hours):</strong> Linear interpolation is usually fine. Temperature doesn’t change that fast.</p> <p><strong>Medium gaps (a day or two):</strong> Regression with environmental predictors. This captures the daily cycle if you have radiation data.</p> <p><strong>Long gaps (weeks+):</strong> Random Forest or similar, but honestly… consider whether you should be filling such long gaps at all. Sometimes it’s better to acknowledge the data is missing.</p> <p><strong>General advice:</strong></p> <ul> <li>Always validate your gap-filling on data where you know the truth</li> <li>Flag gap-filled values in your final dataset</li> <li>Report the uncertainty or error in your gap-filled values</li> <li>Don’t over-fill - sometimes missing data should stay missing</li> </ul> <div style="background-color: #f5f5f5; padding: 10px; border-radius: 5px; margin-bottom: 5px;"> <div class="notice--primary"> <h3> <a href="#which-method-when" class="anchor-heading" aria-labelledby="which-method-when"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Try It Yourself </h3> <p>Compare linear interpolation vs. Random Forest for filling a 24-hour gap in temperature data. Which method captures the daily cycle better?</p> <details> <summary>Solution!</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># The key insight is that linear interpolation can't capture 
# diurnal patterns, while Random Forest (using radiation as 
# a predictor) can.
</span>
<span class="c1"># For a 24-hour gap:
# - Linear interpolation draws a flat line
# - Random Forest predicts warm during day, cool at night
#   (because it learned that high radiation = high temp)
</span>
<span class="c1"># In my experience, Random Forest reduces RMSE by 30-50% 
# compared to linear interpolation for day-long gaps.
</span>
<span class="c1"># But for gaps under 3-6 hours, the methods are often similar
# because temperature hasn't changed much anyway.
</span></code></pre></div> </div> </details> </div> </div><hr /> <h1 id="wrapping-up"> <a href="#wrapping-up" class="anchor-heading" aria-labelledby="wrapping-up"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>Wrapping Up</strong> </h1> <p>We’ve covered a lot of ground here. Let me leave you with the key takeaways:</p> <p><strong>Simple regression</strong> is your starting point. It’s easy to understand, easy to explain, and often good enough for straightforward questions.</p> <p><strong>Multiple regression</strong> lets you account for multiple drivers at once. The coefficients tell you the effect of each variable while controlling for the others.</p> <p><strong>Random Forests</strong> can capture complex patterns that regression misses. They’re particularly good when you don’t know the shape of the relationships in advance.</p> <p><strong>For gap-filling</strong>, match your method to your gap length. Simple interpolation for short gaps, model-based methods for longer ones.</p> <p><strong>Most importantly:</strong> always plot your data, check your assumptions, and validate on independent test data. No amount of fancy statistics can fix bad data or inappropriate models.</p> <p>Good luck with your analyses!</p> <h2 id="where-to-go-from-here"> <a href="#where-to-go-from-here" class="anchor-heading" aria-labelledby="where-to-go-from-here"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Where to Go From Here </h2> <p>If you want to dig deeper:</p> <ul> <li><strong>Generalized Additive Models (GAMs)</strong> let you fit smooth curves instead of straight lines</li> <li><strong>Mixed-effects models</strong> handle hierarchical data (e.g., measurements nested within sites)</li> <li><strong>Gradient Boosting (XGBoost)</strong> often outperforms Random Forests for prediction</li> <li><strong>Time series methods</strong> (ARIMA, etc.) are specifically designed for temporal data</li> </ul> <p>But honestly, you can get surprisingly far with just regression and Random Forests. Master these first before moving on to fancier tools.</p> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
